\documentclass[12pt, a4paper, oneside]{article} % Paper size, default font size and one-sided paper
%\graphicspath{{./Figures/}} % Specifies the directory where pictures are stored
%\usepackage[dcucite]{harvard}
\usepackage{amsmath}
\usepackage{setspace}
\usepackage{pdflscape}
\usepackage{rotating}
\usepackage[flushleft]{threeparttable}
\usepackage{multirow}
\usepackage[comma, sort&compress]{natbib}% Use the natbib reference package - read up on this to edit the reference style; if you want text (e.g. Smith et al., 2012) for the in-text references (instead of numbers), remove 'numbers' 
\usepackage{graphicx}
%\bibliographystyle{plainnat}
\bibliographystyle{agsm}
\usepackage[colorlinks = true, citecolor = blue, linkcolor = blue]{hyperref}
%\hypersetup{urlcolor=blue, colorlinks=true} % Colors hyperlinks in blue - change to black if annoying
%\renewcommand[\harvardurl]{URL: \url}
\usepackage{listings}
\usepackage{color}
\definecolor{mygrey}{gray}{0.95}
\lstset{backgroundcolor=\color{mygrey}}
\begin{document}
\title{Data Science and R Programming}
\author{Rob Hayward}
\date{\today}
\maketitle
\subsection*{Introduction}

This is an introduction to data science and R programming. There are two Coursera courses.  The main clasess can be found \href{https://www.coursera.org/course/datascitoolbox}{Data science toolkit} and \href{https://class.coursera.org/rprog-004}{R Programming}.  

\subsection{Git}
Some rules for adding files
\begin{itemize}
\item git add . adds all new files
\item git add -u updates tracking for files that were changed or deleted
\item git add -A all new files and all changes.
\end{itemize}

If you try to mix different classes in a vector, R will coerce to the lowest common denominator. For example, if you mix numeric and character, you will get two characters; if you try to mix logical and numeric, you will get numeric, if you try to mix logical and character, you will get character. 

A list is a special object.  It can change class.  
<<list>>=
x <- list(1, "a", TRUE, 1 + 4i)
x
@
The elements are indexed by double brackets.  

\subsection{Factors}
Factors are integer vectors with a label. The level is determined by alphabetical order.  Table can be used on factors. "Unclass" will strip the class and take the factor down to an integer. The levels can be set using "level" argument. Elements of an object can usually be named with "name". Lists and matrices can have names.

\subsection{Subsetting}
There are a number of ways to sub-set
\begin{itemize}
\item \lstinline{[} always returns an object of the same class as the original.  Can select more than one element. 
\item \lstinline{[[} is used to extract elements of a list or data frame.  Can only extract a single element and the class may not be an element or a dataframe. 
\item \lstinline{$} used to extract named elements of a list or data frame.  Same attributes as above.
\end{itemize}
Subsetting a matrix will usually return a vector. However, a matrix can be returned by setting \lstinline{drop = FALSE}. This can be important if taking a column of a matrix.  You will get a vector rather than a matrix unless you set \lstinline{drop = FALSE}

<<list2>>=
x <- list(foo = 1:4, bar = 0.6)
x[1]
x[[1]]
x$bar
x[["bar"]]
@
The \lstinline{[[]]} can be used with computed indices. 
<<list3>>=
x <- list(foo = 1:4, bar = 0.6, baz = "hello")
name <- "foo"
x[[name]]
x$name
x$foo
@
<<list4>>=
x <- list(a = list(10, 12, 14), b = c(3.14, 2.18))
x[[c(1, 2)]]
x[[1]][[3]]
x[[c(2, 1)]]
@ 

\subsection{reading data}
One way to speed up reading of large files is to read a small amount and to then create a vector with the column classes to input into the \lstinline{colClasses} section. 

\begin{lstlisting}
initial <- read.table("datatable.txt", nrows = 100)
classes <- sapply(initial, class)
tabAll <- readtable("datatable.txt", colClasses = classes)
\end{lstlisting}

Interfaces with the outside world
\begin{itemize}
\item \lstinline{file} connection to a file
\item \lstinline{gzfile} connection to a gzip compression
\item \lstinline{bzfile} connection to a bzip2 compression
\item \lstinline{url} connection to a web page
\end{itemize}

\subsection{Control Structures}
\begin{itemize}
\item \lstinline{if, else}: testing a condition
\item \lstinline{for}: executing a loop a fixed number of times
\item \lstinline{while}: executing a loop \emph{while} a condition is in place
\item \lstinline{repeat} execute an infinite loop
\item \lstinline{breat}: break the execution of a loop
\item \lstinline{next}: skip an iteration of a loop
\item \lstinline{return}: exit function
\end{itemize}

Nexted loops are inside each other. These are usually going to be used with things like matrices. 

\begin{lstlisting}
x <- matrix(1:6, 2, 3)
for(i in seq_len(nrow(x))) {
  for(j in seq_len(ncol(x))) {
    print(x[i,j])
  }
}
\end{lstlisting}

As another example that will keep flipping a coin until the score goes above or below a number. 

\begin{lstlisting}
z <- 5
while(z >= 3 && z <=10) {
  print(z)
  coin <- rbinm(1, 1, 0.5)
  
  if(coin ==1) { ## randomm walk
    z <- z + 1
  } else {
    z <- z -1
  }
}
\end{lstlisting}

Repeat could be used for running a loop until a certain tolerance is reached.  For example, 
\begin{lstlisting}
x0 <- 1
tol <- 1e-8

repeat {
    x1 computeEstimate()
    
    if(abs(x1 - x0) < tol) {
          break
    } else {
          x0 <- x1
    }
      
}
\end{lstlisting}

This is used in optimistation algorithms. Usually good to add a limit on the number of repeats. For example a loop. 

\section{Functions}
Create an object of a class \lstinline{function}
\emph{Lazy Evaluation} means that the arguments of the function are only evaluated as they are needed. If an artgument is not used or evaluated, there is no problem. However, if the function tries to perform some activity with an argument that does not exist (\lstinline{print} for example), it will throw an error. 

The  \lstinline{...}argument is used to repeated already existing argument defaults.  For example, to extend a copy of the \lstinline{plot} function, 

\begin{lstlisting}
myplot <- function(x, y, type = 'l', ...) {
  plot(x, y, type = type, ...)
}
\end{lstlisting}

They can also be used with generic functions to pass additional arguments to the function.  All elements that are named after the \lstinline{...} have to be named explicitly. 

\subsection{Scoping}
How does R assignm values to symbols? 

For example, 

\begin{lstlisting}
lm <- function{x * x}
lm
\end{lstlisting}

There is already a function called \lstinline{lm} in R. R will search for each of the packages in a list.  This can be found using the \lstinline{search} function. 

<<search>>=
search()
@
This will search the environments.  The first search is the \lstinline{Global Environment} is the workspace.  If you have something in the Global Environment, it will take that first. In this case, it will find the recently defined \lstinline{lm} function in the Global Environment and will use that insteady of the one in \lstinline{stats} package. The \lstinline{base} package is always the last on the list. 

When a package is loaded with the \lstinline{library} function, that package gets put in the second place. R has separate namespaces for functions and other objects. However, in the global environment, it is only possible to have one object for each name. 

Scoping rules deal with the way that values are assigned to variables.  Remember that there are variables that are the arguments of the function and other variables.  R uses \emph{lexical} or \emph{static} scoping rather than \emph{dynamic} scoping. This is particularly useful for statistical calculations. 

For example, 

\begin{lstlisting}
f <- function(x, y) {
  x^2 + y/z
}
\end{lstlisting}

There are two formal arguments \lstinline{x} and \lstinline{y} but it is not clear where \lstinline{z} comes from. This is a free variable that was not defined. Scoping rules define how values are assigned to these \emph{free variables}. 

Scoping rules
\begin{itemize}
\item  The values of the free variables are searched for in the environment in which the variable was defined.  
\item An environment is a collection of (symbol, value) pairs. For example, \lstinline{x} is a symbol and \lstinline{3.1} may be the value. 
\item Every environment has a parent.  It is possible for an environment to have multiple children. 
\item The only environment without a parent is the \emph{empty environment}
\item A function and an environment creates a closure. 
\item Therefore, if the function is defined in the global environment, this will be teh first place that a value for the free variable will be sought. 
\item If this does not work, the next stop is the parent environment. This is the next environment on the search list. If there is no value in the package, the search continues down until the empty environment is reached. 
\item If there is no value in all the environments, an error is returned.
\end{itemize}

This becomes important when functions are defined within other functions.  Therefore, a fucntion can return a function. In this case the function is defined within another fucntion (not the global environment).  

For example, 

<<Func>>=
make.power <- function(n) {
  pow <- function(x) {
    x^n
  }
    pow
}
cube <- make.power(3)
square <- make.power(2)
cube(3)
square(3)
@
Here n is a free variable as it is not defined in the \lstinline{pow} function.  However, it is defined in the \lstinline{make.power} function. 

To explain the difference between lexical and dynamic scoping, look at the following.
<<Func2>>=
y <- 10
f <- function(x) {
  y <- 2
  y^2 + g(x)
}
g(x) <- function(x) {
  
}
f(3)
@
In Lexical scoping, the value of \lstinline{y} in the function \lstinline{g} is looked up in the environment in which the function was defined, in this case the global environment, so the value of \lstinline{y} is 10. 

With dynamic scoping, the value of \lstinline{y} is looked up in the envoronment from which the function was called (sometimes referred to as the \emph{calling environment}.).  In that case the value of \lstinline{y} would be 2. 

if a function is called from the global environment, the global environment and the calling environment are the same so that Lexical scoping can appear to be dynamic scoping. 

The consquences of Lexical scoping
\begin{itemize}
\item All objects in R must be stored in memory.
\item All functions must carry a pointer to their respective defining environment.
\end{itemize}

\subsection{Vectorisation}
This can be a way to avoid looping.  Vectroising makes things simple.  It applies the fuction to each element of a vector.  For example, 

<<Vectorise>>=
x <- 1:4
y <- 6:9
x + y
x > 9
y == 8
x * y 
x / y 
@
For matrix operation
<<matrix>>=
x <- 1:4
y <- 6:9
x * y # element wise multiplication
x / y # element wise multiplication
# True matrix multiplication
x %*% y 
@ 
\subsection{Dates and times}

Times have two formats
\begin{itemize}
\item \lstinline{POSIXct} large integer with the date and time
\item \lstinline{POSIXlt} a list with information on the day of the week, year etc
\end{itemize}
Generic functions \lstinline{weekday, months, quarters} give the day, month name or quarter when applied to a \lstinline{date, POSIXct or POSIXlt} function.  Things can be moved back an forward between the \lstinline{POSIXct} and \lstinline{POSIXlt} functions. 

<<time, tidy=TRUE>>=
x <- Sys.time()
x
p <- as.POSIXlt(x)
names(unclass(p))
p$sec
@ 
The \lstinline{strptime} function will convert dates in character format into date or time objects. 
<<time2>>=
datestring <- c("January 10, 2012 10:40", "December 9, 2011 09:10")
x <- strptime(datestring, "%B %d, %Y %H:%M")
x
class(x)
@
It is possible to use regular operations on dates and times.  However, different classes cannot be mixed.  For example, 

<<Time3>>=
x <- as.Date("2012-01-01")
y <- strptime("9 Jan 2011 11:34.21", "%d %b %Y %H:%S")
x - y
x <- as.POSIXlt(x)
x - y 
@
These operators keep track of very difficult things like leap years, leap seconds daylight savings and time zones. For example, 
<<time4>>=
x <- as.Date("2012-03-01")
y <- as.Date("2012-02-28")
x - y 
x <- as.POSIXct(x)
y <- as.POSIXct(y, tz = "GMT")
y - x
@
The first shows the leap year and the second shows the difference in timezones. 
\subsection{Loop functions}
There are a number of loop functions in R
\begin{itemize}
\item \lstinline{lapply} Look over list and evaluate a function for each element.
\item \lstinline{sapply} Same but simplify the result
\item \lstinline{apply} Margins of an array
\item \lstinline{{tapply} Apply over a subset of a vector
\item \lstinline{mapply} Mulgtivariate version of tapply
\end{itemize}

Also \lstinline{split} is useful. 

These make a lot of use of \emph{annonomous functions}.  These are functions that do not have names. For example, write a function to extract the first column.
<<ann>>=
x <- list(a = matrix(1:4, 2, 2), b = matrix(1:6, 3, 2))
lapply(x, function(elt) elt[,1])
@
\lstinline{sapply} will simplify.  For example, it may return a vector if there is a list of single objects or it may return a matrix. 

Special functions
\begin{itemize}
\item \lstinline{rowSums - apply(x, 1, sum)}
\item \lstinline{rowMean = apply(x, 1, mean)}
\item \lstinline{colSums = apply(x, 2, sum)}
\item \lstinline{colMean = apply(x, 2, mean)}
\end{itemize}

This also works on an array. 

<<array>>=
a <- array(rnorm(2 * 2 * 10), c(2, 2, 10))
apply(a, c(1, 2), mean)
rowMeans(a, dim = 2)
@
There are 10 $2 \times 2$ matrices and we want to take the mean of the matrices.  It will keep the first two dimensions and average over the third dimension.  Hence \lstinline{c(1, 2)}

For \lstinline{tapply} a function can be applied across a subset of a vector.  For example, here there are three different types of random variable and they are associated wtih factors one to three with the \lstinline{gl} function. 

<<factor>>=
x <- c(rnorm(10), runif(10), rnorm(10, 1))
f <- gl(3, 10)
f
tapply(x, f, mean)
@
\lstinline{split} can be used to split a vector into parts that are identified by a factor.  It will return a list. For example, 
<<split>>=
s <- split(airquality, airquality$Month)
sapply(s, function(x) colMeans(x[,c("Ozone", "Solar.R", "Wind")], 
                               na.rm = TRUE))
@
Split can also be done over multiple factors.  For example, 
<<split2>>=
x <- rnorm(10)
f1 <- gl(2, 5)
f2 <- gl(5, 2)
f1
f2
interaction(f1, f2)
str(split(x, list(f1, f2)))
str(split(x, list(f1, f2), drop = TRUE)) # drop empty levels
@
\lstinline{mapply} is a multivariate version.  If there are two lists and the elements of each list go into the function, \lstinline{mapply} may apply. In this case, 
<<mapply>>=
str(mapply)
@
Where \lstinline{FUN} is the function to be applied, \lstinline{...} contains the arguments for it to be applied over; \lstinline{MoreArgs} are more arguments to pass to the function.

<<mapply2>>=
list(rep(1, 4), rep(2, 3), rep(4, 1))
mapply(rep, 1:4, 4:1)
@
\subsection{Logical expressions}
if we have two logical expressions A and B, \lstinline{A | B} will ask whether at least one is true (union); \lstinline{A & B} will ask whether both are TRUE (ie intersection).  \lstinline{!A} is the negaton of A. 

\subsection{Character vectors}
Use the \lstinline{paste} function to put words that are in a character vector together or to join the elements of multiple character vectors.  For example, 

<<myname>>=
my_name <- c("My name", "is", "Rob")
paste(my_name, collapse = " ") # the collapse is the 
# space between.
@
Alternatively, 

<<helloword>>=
paste("Hello", "world!", sep = " ") # now sep is the separate.
@

\subsection{Debugging}
Something is wrong
\begin{itemize}
\item \lstinline{message}: notification/diagnostic 
\item \lstinline{warning}: indication that something is wrong, but not fatally. 
\item \lstinline{error}: a fatal problem has occured
\item \lstinline{condition}: these are all conditions that can be created in the programme
\end{itemize}

\lstinline{invisible} is a function that prevents auto-printing. If this is called on the return object, this will prevent it being returned. 

Debugging tools in R
\begin{itemize}
\item \lstinline{traceback} prints out the function call stack
\item \lstinline{debug} flags a function for debug mode which allows step through. 
\item \lstinline{browser} suspends the execution of the function and puts it in debug mode. 
\item \lstinline{trace} allows you to insert debugging code
\item \lstinline{recover} allows modification of the error behaviour so that function cal stack can be reviewed.
\end{itemize}

<<degug>>=
mean(f)
traceback()
@
\lstinline{traceback} will list that past error.  

\lstinline{debug} will open a workspace within a workspace.  This environment is the function environment. By pessing \lstinline{n} it will move to the next line until the erase.screenror is reached. The debugger can build like a nest on top of another debugger. You can call the debug function on functions within the function. 

\lstinline{recover} will proivide options for going into the code to find out what went wrong. 
\end{document}
