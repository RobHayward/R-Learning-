---
title: "Udemy Machine Learning Course"
author: "Rob Hayward"
date: "19 March 2020"
output: html_document
---

## Section 1

There are examples in the directory

## Section 2
Model problems 
- bias.  most models aim to be unbiased. Sometimes this will depend on the model assumptions (such as linear relationship)
- variance.  There may be a lot of variance in the predictions.  This variance can sometimes be reduced by introducing some bias. 
- Over-fitting.  High bias can lead to over-fitting. This is modelling the sample rather than the underlying structure. The model may be too complex.  Performing well in training and poorly in operation means that it is over fit. 

The model should be tested on training and testing data.  The model will do better on the training data. This is the training error.  This can be related to the test error.  The difference between the two is the generalisation error. This identifies how well this model will work in the field. Many practitioners suggest that the data should be split three ways:  training, calibration and test. Where data is scarce, it is possible to use cross-validation and re sampling techniques. It is best to split randomly.  However, this is not always possible (time serried and where a lot of data comes from one person). 

## Nairve Bayes
This is useful when we have lots of variables (zip codes, industrial sections). An example of this would be *k-grams*.  To assess words you can spilt a document into combed works. These are bag of words and this will count the combinations of words. 

For example, test whether the document was Shakespeare or not based on the two-grams categorisation.  Naive Bayes will return the estimate of probabilities.  This is based on Bayes law

$$P(Shakespears=1| evidence) = P(evidcence | isShakespherar=1) Pr(isShakesphere = 1)/P(evidence)$$

The naive component is the use of the assumption that the evidence items are independent. 
If a two-gram is evident in a document this is an *atom of evidence*.  This is the Bernoulli Model.  True or False.  It is also possible to use a count model. This would give a binomial model. We define smoothed estimates. 

$$lp(isShakesphere = 1) = log((n(isShakesphere-1) + 1) / (n + 2))$$

These adjustments are designed to prevent zeros and log problems. 

We will assess the probability that the document was written by Shakespeare and the probability that it was not written by Shakespeare.  If one probability is above the other, this is our evidence. 

http://www.win-vector.com/blog/2015/01/random-testtrain-split-is-not-always-enough/

The exampe is given in the *NaiveBayes* directory.

Linear regression is less complex than a random forest algorithm.  However, that may mean that there is over fitting.  Test the data on the holdout or test data to see if the root-mean-square error is similar in training and test data. 
